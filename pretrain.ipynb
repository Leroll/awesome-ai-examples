{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 07 21:06:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 25%   51C    P8    26W / 260W |    701MiB / 11264MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       148    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2060    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3208    C+G   ...砑�\\同花顺\\hxexternal.exe    N/A      |\n",
      "|    0   N/A  N/A      3504    C+G   ...86)\\滴答清单\\TickTick.exe    N/A      |\n",
      "|    0   N/A  N/A      5176    C+G   ....0.11.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A      6560    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      7480    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A      8156    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9172    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     10664    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10784    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12868    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     12976    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14292    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     14756    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14896    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19192    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import dataloader\n",
    "from time import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import Pool\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cost(func):\n",
    "    def Wrapper(*arg, **kargs):\n",
    "        t0 = time()\n",
    "        res = func(*arg, **kargs)\n",
    "        t1 = time()\n",
    "        print(f'[{func.__name__}] cost {t1-t0:.2f}s')\n",
    "        \n",
    "        return res\n",
    "    return Wrapper        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "path = '../a_nlp_resource/transformers/bert-base-chinese/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "bert = BertModel.from_pretrained(path).to(device)\n",
    "bert.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vocab\n",
    "\"\"\"\n",
    "vocab = list(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokenizer([\"我的太阳\", '我'], \n",
    "           padding='max_length', \n",
    "           truncation=True, \n",
    "           max_length=20,\n",
    "           return_tensors = 'pt'\n",
    "           ).to(device)\n",
    "y = bert(**x)\n",
    "y[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15360])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].reshape(2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 4638, 1922, 7345,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2769,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"我的太阳\", '我'], \n",
    "           padding='max_length', \n",
    "           truncation=True, \n",
    "           max_length=20,\n",
    "           return_tensors = 'pt'\n",
    "           ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 4638,  103, 7345,  100, 6392,  102,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"我的[MASK]阳[UNK]设\"], \n",
    "           padding='max_length', \n",
    "           truncation=True, \n",
    "           max_length=20,\n",
    "           return_tensors = 'pt'\n",
    "           ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[MASK]'], tokenizer.vocab['[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityDataProcessor:\n",
    "    \"\"\"\n",
    "    处理如下类型数据集\n",
    "    [q1 q2 label]\n",
    "\n",
    "    [idx q1 q2 label]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logger=print):\n",
    "        self.logger = logger\n",
    "\n",
    "    @time_cost\n",
    "    def read_data(self,mode, name, path, sep, encoder='utf-8', has_index=False):\n",
    "        \"\"\"\n",
    "        读取数据,返回 list形式的数据\n",
    "        \n",
    "        mode: 读取数据的方式, \n",
    "              readline \n",
    "              pandas \n",
    "        \"\"\"\n",
    "        self.logger(f'-'*42)\n",
    "        self.logger(f'start to read: [{name}]...')\n",
    "        \n",
    "        if mode == 'readline':\n",
    "            data = self._read_data_by_readline(path=path, \n",
    "                                         sep=sep, \n",
    "                                         encoder=encoder,\n",
    "                                         has_index=has_index)\n",
    "        elif mode == 'pandas':\n",
    "            data = self._read_data_by_pandas(path=path, \n",
    "                                       sep=sep, \n",
    "                                       encoder=encoder)\n",
    "        else:\n",
    "            raise Exception('mode的值有误')\n",
    "        \n",
    "        # logs\n",
    "        self.logger(f'finish reading: [{name}]')\n",
    "        self.logger('nums:',len(data))\n",
    "        for i in range(5):\n",
    "            self.logger(data[i])\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _read_data_by_readline(self, path, sep, encoder='utf-8', has_index=False):\n",
    "        data = []\n",
    "        with open(path, encoding=encoder) as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                try:\n",
    "                    # 预处理\n",
    "                    line = line.strip()\n",
    "                    line = line.replace('\\ufeff', '')\n",
    "\n",
    "                    if has_index:\n",
    "                        idx, q1, q2, label = line.split(sep)\n",
    "                    else:\n",
    "                        q1, q2, label = line.split(sep)\n",
    "                    data.append([q1, q2, label])\n",
    "\n",
    "                    line = f.readline()\n",
    "                except Exception as e:\n",
    "                    print(f'line: {line}')\n",
    "                    print('-'*42)\n",
    "                    print(e)\n",
    "                    sys.exit()     \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _read_data_by_pandas(self,path, sep, encoder='utf-8'):\n",
    "        data = pd.read_csv(path, sep=sep, encoding=encoder)\n",
    "        data = data.to_numpy().tolist()\n",
    "        return data\n",
    "        \n",
    "\n",
    "    def create_dataloader(self, data, batch_size, is_shuffle):\n",
    "        dataloader = torch.utils.data.DataLoader(data,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=is_shuffle)\n",
    "        return dataloader\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    #预处理\n",
    "    ############################################\n",
    "    def preprocessing(self, text):\n",
    "        \"\"\"\n",
    "        单句处理\n",
    "        \"\"\"\n",
    "        global vocab\n",
    "        \n",
    "        res = ''\n",
    "        for i in text: \n",
    "            # 大写字母vocab里面没有\n",
    "            i = i.lower() \n",
    "            \n",
    "            # punctuation \n",
    "            if i =='…': \n",
    "                i = '.'\n",
    "            elif i in [\"'\",'‘','’','“','”']: \n",
    "                i = \"'\"\n",
    "            elif i in ['—', '―', '—', '`']: # 注意'-'互相不一样\n",
    "                i = ','\n",
    "            \n",
    "            # char\n",
    "            char_correct = {\n",
    "                '壋':'增', '笫':'第', '囙':'回',\n",
    "                '呮':'呗', '嚒':'么', '睌':'晚',\n",
    "                '谝':'骗', '鍀':'得', '昰':'是',\n",
    "                '伲':'呢', '肔':'服', '凊':'清',\n",
    "                '挷':'绑', '亊':'事', '腨':'用',\n",
    "                '戗':'钱', '玏':'功', '筘':'扣',\n",
    "                '鈤':'日', '颃':'领', '讠':'之',\n",
    "                '扥':'在', '螚':'能', '甪':'用',\n",
    "                '茌':'花', '泝':'没', '牫':'我',\n",
    "                '孒':'了', '镸':'长', '欹':'款',\n",
    "                '刭':'到', '幵':'开', '怩':'呢',\n",
    "                '绐':'给', '弍':'式', '淸':'清',\n",
    "                '夂':'久', '叧':'另', '徣':'借',\n",
    "                '冋':'回', '敉':'粒', '埭':'贷',\n",
    "                '仧':'卡', '頟':'额', '捿':'捷',\n",
    "                '鳓':'嘞', '䃼':'补', '囯':'国',\n",
    "                '吿':'告'\n",
    "            }\n",
    "            if i in char_correct:\n",
    "                i = char_correct[i]\n",
    "                    \n",
    "            # nonsense letter\n",
    "            if i in [' ', ' ', '　', '　',' ',' ',\n",
    "                     chr(8198), chr(65039), chr(8237), chr(8236),  # 一串打出来都是空格\n",
    "                     '\\u200d', '\\x08','', '', \n",
    "                     '∨', '乛','∵', chr(8198),]:\n",
    "                continue\n",
    "                \n",
    "            # UNK\n",
    "            if i not in vocab:\n",
    "                self.logger(text,'|',ord(i),'|',i)\n",
    "                i = '[UNK]' # 这个UNK后面的 tokenizer可以处理\n",
    "                    \n",
    "                \n",
    "            res += i \n",
    "        \n",
    "        return res  \n",
    "    \n",
    "   \n",
    "    def preprocess_similarity_data(self, data):\n",
    "        \"\"\"\n",
    "        预处理形如 [[q1_1,q2_1,label_1], [q1_2,q2_2,label_2]] 的数据\n",
    "        \"\"\"\n",
    "        q1,q2,label = list(zip(*data))\n",
    "        q1 = [self.preprocessing(q) for q in q1]\n",
    "        self.logger('q1 处理完毕')\n",
    "        q2 = [self.preprocessing(q) for q in q2]\n",
    "        self.logger('q2 处理完毕')\n",
    "        \n",
    "        res = list(zip(q1,q2,label))\n",
    "        return res\n",
    "    \n",
    "    @time_cost\n",
    "    def multi(self, work_num, func, data):\n",
    "        \"\"\"\n",
    "        目前函数输入只有 data \n",
    "        \"\"\"\n",
    "        per_lenght = len(data)//(work_num-1) # 最后还有一个尾巴余量给最后一个work\n",
    "\n",
    "        p = Pool()\n",
    "        p_res = []\n",
    "        for i in range(work_num):\n",
    "            begin = per_lenght*i\n",
    "            end = per_lenght*(i+1)\n",
    "            p_res.append(p.apply_async(func, args=(data[begin:end],)))\n",
    "        p.close()\n",
    "        p.join()\n",
    "        \n",
    "        res = []\n",
    "        for i in range(work_num):\n",
    "            res.append(p_res[i].get())\n",
    "        \n",
    "        # 当 data 是 [[q1_1,q2_1,label_1], [q1_2,q2_2,label_2]] 数据时\n",
    "        res = [j for i in res for j in i]\n",
    "        return res\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################################################\n",
    "    # mask data\n",
    "    ##################################################\n",
    "    \n",
    "    def get_masked_text(self, text):\n",
    "        \"\"\"\n",
    "        生成masked后的输入inputs,\n",
    "        和对应的输出标签 labels, 里面0代表不需要预测,在计算loss时需要忽略\n",
    "        \"\"\"\n",
    "        global vocab,tokenizers\n",
    "\n",
    "        inputs = ''\n",
    "        labels = []\n",
    "\n",
    "        for i in text:\n",
    "            if i not in vocab:\n",
    "                print(f'UNK | {text} | {ord(i)} | {i}')\n",
    "                i = '[UNK]'\n",
    "            \n",
    "            # preprocessing\n",
    "            r = np.random.random()\n",
    "            i_id = tokenizer.vocab[i]\n",
    "            if r <= 0.15*0.8:\n",
    "                inputs += '[MASK]'\n",
    "                labels.append(i_id)\n",
    "            elif r <= 0.15*0.9:\n",
    "                inputs += np.random.choice(list(text))\n",
    "                labels.append(i_id)\n",
    "            elif r <= 0.15:\n",
    "                inputs += i\n",
    "                labels.append(i_id)\n",
    "            else:\n",
    "                inputs += i\n",
    "                labels.append(0)\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    @time_cost\n",
    "    def get_masked_data(self, data):\n",
    "        \"\"\"\n",
    "        data = [q1,q2,q3,...]\n",
    "        \"\"\"\n",
    "        input_data = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in data:\n",
    "            temp_input, temp_labels = self.get_masked_text(i)\n",
    "            input_data.append(temp_input)\n",
    "            labels.append(temp_labels)\n",
    "            \n",
    "        self.logger('Inputs & labels:')\n",
    "        for i in range(5):\n",
    "            self.logger(input_data[i])\n",
    "            self.logger(labels[i])\n",
    "    \n",
    "        return input_data, labels\n",
    "    \n",
    "data_processor = SimilarityDataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = SimilarityDataProcessor(logger=print) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "start to read: [atec]...\n",
      "finish reading: [atec]\n",
      "nums: 39346\n",
      "['怎么更改花呗手机号码', '我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号', '1']\n",
      "['也开不了花呗，就这样了？完事了', '真的嘛？就是花呗付款', '0']\n",
      "['花呗冻结以后还能开通吗', '我的条件可以开通花呗借款吗', '0']\n",
      "['如何得知关闭借呗', '想永久关闭借呗', '0']\n",
      "['花呗扫码付钱', '二维码扫描可以用花呗吗', '0']\n",
      "[read_data] cost 0.05s\n",
      "------------------------------------------\n",
      "start to read: [atec]...\n",
      "finish reading: [atec]\n",
      "nums: 63131\n",
      "['为何我无法申请开通花呗信用卡收款', '支付宝开通信用卡花呗收款不符合条件怎么回事', '1']\n",
      "['花呗分期付款会影响使用吗', '花呗分期有什么影响吗', '0']\n",
      "['为什么我花呗没有临时额度', '花呗没有临时额度怎么可以负', '0']\n",
      "['能不能开花呗老兄', '花呗逾期了还能开通', '0']\n",
      "['我的怎么开通花呗收钱', '这个花呗是个什么啥？我没开通 我怎么有账单', '0']\n",
      "[read_data] cost 0.06s\n"
     ]
    }
   ],
   "source": [
    "atec = data_processor.read_data(mode='readline',\n",
    "                                name='atec', \n",
    "                                path='../a_nlp_resource/dataset/ATEC/atec_nlp_sim_train.csv', \n",
    "                                sep='\\t',\n",
    "                                encoder='utf-8',\n",
    "                                has_index=True)\n",
    "\n",
    "atec_add = data_processor.read_data(mode='readline',\n",
    "                                name='atec', \n",
    "                                path='../a_nlp_resource/dataset/ATEC/atec_nlp_sim_train_add.csv', \n",
    "                                sep='\\t',\n",
    "                                encoder='utf-8',\n",
    "                                has_index=True)\n",
    "atec = atec + atec_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 处理完毕\n",
      "q2 处理完毕\n"
     ]
    }
   ],
   "source": [
    "atec = data_processor.preprocess_similarity_data(atec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bq_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "start to read: [bq_corpus_train]...\n",
      "finish reading: [bq_corpus_train]\n",
      "nums: 100000\n",
      "['用微信都6年，微信没有微粒贷功能', '4。  号码来微粒贷', 0]\n",
      "['微信消费算吗', '还有多少钱没还', 0]\n",
      "['交易密码忘记了找回密码绑定的手机卡也掉了', '怎么最近安全老是要改密码呢好麻烦', 0]\n",
      "['你好 我昨天晚上申请的没有打电话给我 今天之内一定会打吗？', '什么时候可以到账', 0]\n",
      "['“微粒贷开通\"', '你好，我的微粒贷怎么没有开通呢', 0]\n",
      "[read_data] cost 0.11s\n",
      "------------------------------------------\n",
      "start to read: [bq_corpus_val]...\n",
      "finish reading: [bq_corpus_val]\n",
      "nums: 10000\n",
      "['不要借了我是试试看能否操作的', '借款审核期间能否取消借款', 0]\n",
      "['亲怎样才能在钱包里有微粒货的图标呢', '借不到', 0]\n",
      "['你好，我还款银行怎么更换', '怎么更换绑定还款的卡', 1]\n",
      "['我的借贷额度，怎么减少了呢？', '微粒贷额度怎么才能降低', 0]\n",
      "['什么时候可以知道借款成功', '2.多笔借款', 0]\n",
      "[read_data] cost 0.14s\n",
      "------------------------------------------\n",
      "start to read: [bq_corpus_test]...\n",
      "finish reading: [bq_corpus_test]\n",
      "nums: 10000\n",
      "['为什么我无法看到额度', '为什么开通了却没有额度', 0]\n",
      "['为啥换不了', '为两次还都提示失败呢', 0]\n",
      "['借了钱，但还没有通过，可以取消吗？', '可否取消', 1]\n",
      "['为什么我申请额度输入密码就一直是那个页面', '为什么要输入支付密码来验证', 0]\n",
      "['今天借 明天还款可以？', '今天借明天还要手续费吗', 0]\n",
      "[read_data] cost 0.03s\n"
     ]
    }
   ],
   "source": [
    "path = './data/bq_corpus/'\n",
    "bq_corpus_train = data_processor.read_data(mode='pandas',\n",
    "                                           name='bq_corpus_train', \n",
    "                                           path=path+'train.csv', \n",
    "                                           sep=',',\n",
    "                                           encoder='utf-8')\n",
    "\n",
    "bq_corpus_val = data_processor.read_data(mode='pandas',\n",
    "                                         name='bq_corpus_val', \n",
    "                                         path=path+'dev.csv', \n",
    "                                         sep=',',\n",
    "                                         encoder='utf-8')\n",
    "\n",
    "bq_corpus_test = data_processor.read_data(mode='pandas',\n",
    "                                          name='bq_corpus_test', \n",
    "                                          path=path+'test.csv', \n",
    "                                          sep=',',\n",
    "                                          encoder='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 处理完毕\n",
      "q2 处理完毕\n"
     ]
    }
   ],
   "source": [
    "bq_corpus_train = data_processor.preprocess_similarity_data(bq_corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 处理完毕\n",
      "q2 处理完毕\n"
     ]
    }
   ],
   "source": [
    "bq_corpus_val = data_processor.preprocess_similarity_data(bq_corpus_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(･ิϖ･ิ)っ看不到 | 3636 | ิ\n",
      "(･ิϖ･ิ)っ看不到 | 982 | ϖ\n",
      "(･ิϖ･ิ)っ看不到 | 3636 | ิ\n",
      "伸请微粒货我到疷要等多久帮忙查下 | 30135 | 疷\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "(･ิϖ･ิ)っ看不到 | 3636 | ิ\n",
      "(･ิϖ･ิ)っ看不到 | 982 | ϖ\n",
      "(･ิϖ･ิ)っ看不到 | 3636 | ิ\n",
      "如何还歀 | 27456 | 歀\n",
      "伸请微粒货我到疷要等多久帮忙查下 | 30135 | 疷\n",
      "如何还歀 | 27456 | 歀\n",
      "q1 处理完毕\n",
      "如何还歀 | 27456 | 歀\n",
      "强烈要求增额﹉ | 65097 | ﹉\n",
      "强烈要求增额﹉ | 65097 | ﹉\n",
      "为什么我没有微鞡货 我借不了款 | 38817 | 鞡\n",
      "如何还歀 | 27456 | 歀\n",
      "如何还歀 | 27456 | 歀\n",
      "2⃣️十几分钟了都没有消息！还说三分钟搞定？？？ | 8419 | ⃣\n",
      "强烈要求增额﹉ | 65097 | ﹉\n",
      "q2 处理完毕\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test 数据集也可以处理, 不过只使用训练集的经验知识来处理\n",
    "\"\"\"\n",
    "bq_corpus_test = data_processor.preprocess_similarity_data(bq_corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlm dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424954"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_data = (list(zip(*bq_corpus_train))[0] \n",
    "            + list(zip(*bq_corpus_train))[1]\n",
    "            + list(zip(*bq_corpus_val))[0]\n",
    "            + list(zip(*bq_corpus_val))[1]\n",
    "            + list(zip(*atec))[0]\n",
    "            + list(zip(*atec))[1])\n",
    "len(mlm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227826\n",
      "花呗人脸验证，是本人为什么验证不了\n",
      "借呗申请怎么填大学\n",
      "今天蚂蚁借呗还款日到了，但没扣款\n",
      "花呗如何重新绑定手机号\n",
      "我每月都会提前还款，为什么我的蚂蚁借呗额度降低了\n"
     ]
    }
   ],
   "source": [
    "mlm_data = list(set(mlm_data))\n",
    "print(len(mlm_data))\n",
    "for i in range(5):\n",
    "    print(mlm_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2635d0be128>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(mlm_data).apply(lambda x : len(x)).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('我[MASK][MASK]国心', [0, 4638, 704, 0, 0])\n",
      "('我的中国心', [0, 0, 0, 0, 0])\n",
      "('我国中国心', [2769, 4638, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(data_processor.get_masked_data('我的中国心'))\n",
    "print(data_processor.get_masked_data('我的中国心'))\n",
    "print(data_processor.get_masked_data('我的中国心'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs & labels:\n",
      "花呗人脸验[MASK][MASK]是本人为[MASK]么验证不了\n",
      "[0, 0, 0, 0, 0, 6395, 8024, 0, 0, 0, 0, 784, 0, 0, 0, 0, 0]\n",
      "借呗申请怎么填大学\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "今天蚂蚁借呗还款日[MASK]了[MASK]但没扣款\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1168, 0, 8024, 0, 0, 0, 0]\n",
      "[MASK]呗如何重新绑定号机号\n",
      "[5709, 0, 0, 0, 0, 0, 0, 0, 2797, 0, 0]\n",
      "我每月都会提前还款，为什么我的蚂蚁借[MASK]额度降低了\n",
      "[0, 0, 0, 0, 0, 2990, 0, 0, 0, 0, 0, 0, 720, 0, 0, 0, 0, 0, 1446, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "mlm_input, mlm_label = data_processor.get_masked_data(mlm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlm_label']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlm_input, 'mlm_input')\n",
    "joblib.dump(mlm_label, 'mlm_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['用微信都6年，微信没有微粒贷功能', '4。  号码来微粒贷', 0],\n",
       " ['微信消费算吗', '还有多少钱没还', 0],\n",
       " ['交易密码忘记了找回密码绑定的手机卡也掉了', '怎么最近安全老是要改密码呢好麻烦', 0],\n",
       " ['你好 我昨天晚上申请的没有打电话给我 今天之内一定会打吗？', '什么时候可以到账', 0],\n",
       " ['“微粒贷开通\"', '你好，我的微粒贷怎么没有开通呢', 0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = bq_corpus_train\n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4。  号码来微粒贷', '用微信都6年，微信没有微粒贷功能', 0),\n",
       " ('还有多少钱没还', '微信消费算吗', 0),\n",
       " ('怎么最近安全老是要改密码呢好麻烦', '交易密码忘记了找回密码绑定的手机卡也掉了', 0),\n",
       " ('什么时候可以到账', '你好 我昨天晚上申请的没有打电话给我 今天之内一定会打吗？', 0),\n",
       " ('你好，我的微粒贷怎么没有开通呢', '“微粒贷开通\"', 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_change = list(zip(*train))\n",
    "train_change = [train_change[1],train_change[0],train_change[2]]\n",
    "train_change = list(zip(*train_change))\n",
    "train_change[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train+train_change\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "val, test\n",
    "\"\"\"\n",
    "val = bq_corpus_val\n",
    "test = bq_corpus_test\n",
    "\n",
    "len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f3365d0a8957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_loader = data_processor.create_dataloader(train, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                 is_shuffle=True)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m val_loader = data_processor.create_dataloader(val, \n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_processor' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = data_processor.create_dataloader(train, \n",
    "                                                batch_size=batch_size, \n",
    "                                                is_shuffle=True)\n",
    "\n",
    "val_loader = data_processor.create_dataloader(val, \n",
    "                                              batch_size=batch_size, \n",
    "                                              is_shuffle=False)\n",
    "\n",
    "test_loader = data_processor.create_dataloader(test, \n",
    "                                               batch_size=batch_size, \n",
    "                                               is_shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'max_len':50,\n",
    "    'hidden_size':768,\n",
    "    'embedding_size': 21128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MlmBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        global bert, tokenizer, model_config\n",
    "   \n",
    "        self.final_part = nn.Sequential(OrderedDict([\n",
    "            ('final_Linear', \n",
    "             nn.Linear(model_config['hidden_size'],model_config['hidden_size'], bias=True)),\n",
    "            ('final_layernorm', \n",
    "             nn.LayerNorm(model_config['hidden_size'],eps=1e-12)),\n",
    "            ('final_embedding', \n",
    "             nn.Linear(model_config['hidden_size'], model_config['embedding_size'], bias=False))  \n",
    "        ]))\n",
    "        \n",
    "        embedding_p = [p for p in bert.embeddings.word_embeddings.parameters()][0].T\n",
    "        final_part.final_embedding.weight.data=embedding_p\n",
    "        \n",
    "\n",
    "    def forward(self,q1,q2):\n",
    "        \n",
    "        \n",
    "        \n",
    "        return h   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def save(self, path='./sbert.model'):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load(self, path='./sbert.model'):\n",
    "        self.load_state_dict(torch.load(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.991px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "376px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
